---
title: Replication Architecture
sidebar_position: 0
image: og/docs/concepts.jpg
# tags: ['architecture']
---

:::info `v1.17` で追加
:::

Weaviate は、[レプリケーション ファクター](../../manage-collections/multi-node-setup.mdx#replication-settings) を 1 より大きく設定することで、マルチノード クラスター間でのデータ レプリケーションを実現します。これにより、[高可用性](./motivation.md#high-availability-redundancy) などのさまざまな[利点](./motivation.md)を得ることができます。データベースのレプリケーションは、信頼性、スケーラビリティ、およびパフォーマンスを向上させます。

Weaviate では複数のレプリケーション アーキテクチャを採用しています。

- [クラスターメタデータのレプリケーション](./consistency.md#cluster-metadata) は [Raft](https://raft.github.io/) コンセンサス アルゴリズムによって管理されます。
- [データのレプリケーション](./consistency.md#data-objects) は[調整可能](./consistency.md)で、リーダーレスです。

<details>
  <summary>クラスター <code>metadata</code> とは？</summary>

Weaviate クラスターの `metadata` には、コレクション定義やテナントのアクティビティ ステータスが含まれます。  
<br/>

すべてのクラスター メタデータは、レプリケーション ファクターに関係なく常に全ノードに複製されます。  
<br/>

これはオブジェクトの作成時間など、オブジェクト メタデータとは異なる点に注意してください。オブジェクト メタデータは、指定されたレプリケーション ファクターに従い、オブジェクト データとともに保存されます。

</details>

この「レプリケーション アーキテクチャ」セクションでは、以下の情報を確認できます。

* **一般概念** （このページ）
  * レプリケーションとは？
  * CAP 定理
  * Weaviate にレプリケーションが必要な理由
  * レプリケーションとシャーディングの違い
  * Weaviate におけるレプリケーションの仕組み
  * ロードマップ

* **[ユースケース](./motivation.md)**
  * モチベーション
  * 高可用性
  * 読み取りスループットの向上
  * ゼロダウンタイム アップグレード
  * リージョン近接性

* **[理念](./philosophy.md)**
  * 典型的な Weaviate のユースケース
  * リーダーレス アーキテクチャを採用する理由
  * 段階的なロールアウト
  * 大規模テスト

* **[クラスター アーキテクチャ](./cluster-architecture.md)**
  * リーダーレス設計
  * レプリケーション ファクター
  * 書き込み・読み取り操作

* **[整合性](./consistency.md)**
  * クラスターメタデータ
  * データ オブジェクト
  * リペア

* **[マルチデータセンター](./multi-dc.md)**
  * リージョン近接性

## レプリケーションとは？

<p align="center"><img src="/img/docs/replication-architecture/replication-rf3-c-QUORUM.png" alt="レプリケーション設定例" width="75%"/></p>

データベース レプリケーションとは、同一のデータ ポイントをクラスター内の複数ノードに保持することを指します。

その結果、システムは分散データベースになります。分散データベースは複数のノードで構成され、各ノードがデータのコピーを保持できます。そのため、1 台のノード（サーバー）がダウンしても、他のノードからデータにアクセスできます。さらに、レプリケーションによってクエリ スループットを向上させることも可能です。

## CAP 定理

レプリケーションを導入する主目的は信頼性の向上です。[Eric Brewer](https://en.wikipedia.org/wiki/Eric_Brewer_(scientist)) は、分散データベースにおける信頼性には制限があるとし、それを [CAP 定理](https://en.wikipedia.org/wiki/CAP_theorem) で説明しました。CAP 定理では、分散データベースは次の 3 つの保証のうち 2 つしか同時に提供できないとします。  
* **Consistency (C) 一貫性** - すべての読み取りが最新の書き込み、またはエラーを受け取り、すべてのノードが同じタイミングで同じデータを確認できることを保証します。  
* **Availability (A) 可用性** - 常にエラーのない応答を返しますが、必ずしも最新の書き込みを含むとは限りません。  
* **Partition tolerance (P) 分断耐性** - ノード間で任意の数のメッセージがドロップ（または遅延）してもシステムが動作を継続できることを示します。

<p align="center"><img src="/img/docs/replication-architecture/repliction-cap.png" alt="CAP 定理" width="60%"/></p>

理想的には Weaviate のようなデータベースには最高レベルの信頼性が求められますが、整合性・可用性・分断耐性のトレードオフによって制限されます。

### 一貫性と可用性のトレードオフ

:::tip
Consistency (C)、Availability (A)、Partition tolerance (P) のうち、同時に保証できるのは 2 つだけです。

分断耐性が必須であることを前提に、残る 2 つのうちどちらを優先するかを検討してください。
:::

整合性、可用性、分断耐性の 3 つのうち 2 つしか保証できません。クラスターは本質的にネットワーク パーティションを伴う分散システムであるため、設計上は **整合性 (C)** と **可用性 (A)** のどちらを優先するかを選択することになります。

**整合性** を可用性より優先すると、ネットワーク パーティションによって最新データである保証が得られない場合、データベースはエラーやタイムアウトを返します。**可用性** を整合性より優先すると、ネットワーク パーティションが発生しても常にクエリを処理し、最新データである保証がなくても可能な限り最新バージョンを返そうとします。

銀行口座の取引データなど、クリティカルなデータを扱う場合は C over A が望まれます。トランザクション データでは常に整合性が保証されるべきだからです（ノードがダウンしている間に取引を行うと残高が正しくなくなる恐れがあります）。

重要度が低いデータでは A over C を選択することもあります。たとえばメッセージング サービスでは、古いデータが一時的に表示されても問題なく、低レイテンシで高可用性を維持することが求められます。

Weaviate は一般的に後者の設計思想に従います。Weaviate はクリティカルではないデータを扱い、近似検索のためのセカンダリ データベースとして使用されるケースが多いためです。この設計理由の詳細は [理念](./philosophy.md) を参照してください。ただし Weaviate では、用途に応じて [調整可能な整合性](./consistency.md#tunable-consistency-strategies) オプションを利用できます。

## Weaviate にレプリケーションが必要な理由

Weaviate はデータベースとして、ユーザーのリクエストに対して信頼できる回答を提供する必要があります。前述のとおり、データベースの信頼性はいくつかの要素で構成されます。以下は、Weaviate でレプリケーションが望ましいユースケースです。詳細は [レプリケーションのユースケース（モチベーション）](./motivation.md) ページをご覧ください。

1. **高可用性（冗長性）**  
   分散（レプリケーションされた）データベース構成では、1 台のサーバー ノードがダウンしてもサービスは中断されません。データベースは引き続き利用可能で、読み取りクエリは利用可能なノードへ（ユーザーには気付かれずに）リダイレクトされます。  
2. **読み取りスループットの向上**  
   データベース構成にサーバー ノードを追加すると、スループットもそれに応じてスケールします。サーバー ノードが多いほど、システムが処理できるユーザー（読み取り操作）の数が増えます。整合性レベル `ONE` で読み込む場合、レプリケーション ファクター（すなわちデータベース サーバー ノード数）を増やすとスループットが線形に向上します。  
3. **ゼロダウンタイム アップグレード**  
   レプリケーションがない場合、Weaviate インスタンスをアップグレードするときにダウンタイムが発生します。単一ノードは停止し、アップデートし、再起動してから再びサービスを開始する必要があるためです。レプリケーションがあればローリング アップデートを実施でき、常に最大 1 台のノードだけが利用不可となり、他のノードはトラフィックを処理し続けられます。  
4. **リージョン近接性**  
   ユーザーが異なる地域（例としてアイスランドとオーストラリア）に存在すると、データベース サーバーとの物理距離のため、すべてのユーザーに低レイテンシを保証することはできません。分散データベースでは、異なる地域にノードを配置してレイテンシを短縮できます。これはレプリケーションのマルチデータセンター機能に依存します。
## レプリケーションとシャーディング

レプリケーションは [シャーディング](../cluster.md) とは異なります。シャーディングは水平スケーリングを指し、 Weaviate には  v1.8  で導入されました。

* **Replication** はデータを複数のサーバーノードにコピーします。 Weaviate ではこれによりデータの可用性が高まり、単一ノード障害時の冗長性が確保されます。クエリのスループットもレプリケーションで改善できます。  
* **Sharding** はデータを分割し、そのデータ片 (シャード) を複数のレプリカセットに送ることでサーバー間の水平スケーリングを行います。データは分割され、すべてのシャードを合わせて完全なデータセットになります。 Weaviate でシャーディングを使用すると、大規模データセットの運用やインポート速度の向上が可能です。

<p align="center"><img src="/img/docs/replication-architecture/replication-replication-vs-sharding.png" alt="レプリケーションとシャーディング" width="60%"/></p>

レプリケーションとシャーディングは組み合わせて利用でき、スループットと可用性の向上、インポート速度の向上、大規模データセットへの対応が可能です。たとえば、データベースを  3  レプリカ、シャード数を  3  に設定すると、合計  9  シャードになり、各サーバーノードが異なる  3  つのシャードを保持します。

## Weaviate におけるレプリケーションの動作

### クラスタメタデータのレプリケーション

Weaviate のクラスタメタデータの変更は Raft により管理され、クラスタ全体で一貫性を提供します (これにはコレクション定義やテナントのアクティビティステータスが含まれます)。

Weaviate  では  `v1.25`  から、クラスタメタデータの変更は Raft コンセンサスアルゴリズムでコミットされます。 Raft はリーダーベースのコンセンサスアルゴリズムで、リーダーノードがクラスタメタデータの変更を担当します。 Raft は (少数の) ノード障害が発生しても、変更がクラスタ全体で一貫していることを保証します。

<details>
  <summary>v1.25 以前のメタデータレプリケーション</summary>

Weaviate  `v1.25`  より前は、各クラスタメタデータの変更は 2 フェーズコミットによる分散トランザクションで記録されていました。  
<br/>

これは同期プロセスであり、すべてのノードが変更を承認して初めてコミットされます。このアーキテクチャでは、任意のノードがダウンしているとメタデータ操作が一時的にできなくなります。さらに、同時に処理できる操作は  1  件のみでした。  

Weaviate  `v1.24`  以前をお使いの場合は、クラスタメタデータ変更に Raft コンセンサスアルゴリズムを利用するために [ `v1.25`  へアップグレード](/deploy/migration/weaviate-1-25.md) できます。

</details>

### データレプリケーション

Weaviate では、一般に整合性よりも可用性を重視します。 Weaviate のデータレプリケーションはリーダーレス設計で、プライマリやセカンダリという概念がありません。データの読み書き時にクライアントは  1  台以上のノードに接続します。ユーザーとノードの間にはロードバランサーがあり、ユーザーはどのノードと通信しているかを意識する必要がありません (ユーザーが誤ったノードにリクエストした場合、 Weaviate が内部で転送します)。

読み取りまたは書き込み操作を承認する必要があるノード数は (  v1.18  から) `ONE`、`QUORUM` (n/2+1) 、`ALL` に調整できます。整合性レベルを `ALL` に設定して書き込む場合、データベースは同期的に動作します。 `ALL` 以外に設定した場合 (  v1.18  以降可能) 、ユーザー視点では非同期で書き込まれます。

レプリカ数はノード数 (クラスタサイズ) と一致する必要はありません。 Weaviate ではコレクション単位でデータを分割できます。これは [シャーディングとは異なる](#replication-vs-sharding) ことに注意してください。

Weaviate におけるレプリケーションの詳細は、 [Philosophy](./philosophy.md) 、 [Cluster Architecture](./cluster-architecture.md) 、 [Consistency](./consistency.md) を参照してください。

## Weaviate でレプリケーションを利用する方法

[レプリケーションの設定方法](/deploy/configuration/replication.md) を参照してください。コレクション定義でレプリケーションを有効にできます。クエリでは [希望する整合性レベルを指定](../../search/basics.md#replication) することが可能です。

## ロードマップ

* 未定
  * マルチデータセンター レプリケーション (この機能への投票は [こちら](https://github.com/weaviate/weaviate/issues/2436) から)

## 関連ページ
- [設定: レプリケーション](/deploy/configuration/replication.md)

## 質問とフィードバック

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>